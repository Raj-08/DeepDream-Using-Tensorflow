{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First check the Python version\n",
    "import sys\n",
    "if sys.version_info < (3,4):\n",
    "    print('You are running an older version of Python!\\n\\n',\n",
    "          'You should consider updating to Python 3.4.0 or',\n",
    "          'higher as the libraries built for this course',\n",
    "          'have only been tested in Python 3.4 and higher.\\n')\n",
    "    print('Try installing the Python 3.5 version of anaconda'\n",
    "          'and then restart `jupyter notebook`:\\n',\n",
    "          'https://www.continuum.io/downloads\\n\\n')\n",
    "\n",
    "# Now get necessary libraries\n",
    "try:\n",
    "    import os\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from skimage.transform import resize\n",
    "    from skimage import data\n",
    "    from scipy.misc import imresize\n",
    "    from scipy.ndimage.filters import gaussian_filter\n",
    "    import IPython.display as ipyd\n",
    "    import tensorflow as tf\n",
    "    from libs import utils, gif, datasets, dataset_utils, vae, dft, vgg16, nb_utils\n",
    "except ImportError:\n",
    "    print(\"Make sure you have started notebook in the same directory\",\n",
    "          \"as the provided zip file which includes the 'libs' folder\",\n",
    "          \"and the file 'utils.py' inside of it.  You will NOT be able\",\n",
    "          \"to complete this assignment unless you restart jupyter\",\n",
    "          \"notebook inside the directory created by extracting\",\n",
    "          \"the zip file or cloning the github repo.  If you are still\")\n",
    "\n",
    "# We'll tell matplotlib to inline any drawn figures like so:\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# Bit of formatting because I don't like the default inline code style:\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"\"\"<style> .rendered_html code { \n",
    "    padding: 2px 4px;\n",
    "    color: #c7254e;\n",
    "    background-color: #f9f2f4;\n",
    "    border-radius: 4px;\n",
    "} </style>\"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from libs import vgg16, inception, i2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = inception.get_inception_model(version='v5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "og = plt.imread('raj1.jpg')[..., :3]\n",
    "plt.imshow(og)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "og = plt.imread('raj1.jpg')[..., :3]\n",
    "plt.imshow(og)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "deprocessed = net['preprocess'](img)\n",
    "plt.imshow(deprocessed)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = vgg16.get_vgg_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "device = '/cpu:0'\n",
    "\n",
    "g = tf.Graph()\n",
    "\n",
    "\n",
    "with tf.Session(graph=g) as sess, g.device(device):\n",
    "    \n",
    "    tf.import_graph_def(net['graph_def'], name='net')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = ['net/pool1:0', 'net/pool2:0', 'net/pool3:0']\n",
    "\n",
    "# Let's print them\n",
    "print(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = g.get_tensor_by_name('net/images:0');\n",
    "\n",
    "assert(x.name == 'net/images:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_gradient(img, x, feature, g, device='/cpu:0'):\n",
    "   \n",
    "    with tf.Session(graph=g) as sess, g.device(device):\n",
    "        saliency = tf.gradients(tf.reduce_mean(feature), x)\n",
    "        this_res = sess.run(saliency[0], feed_dict={x: img})\n",
    "        grad = this_res[0] / np.max(np.abs(this_res))\n",
    "        return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "og = plt.imread('raj1.jpg')[..., :3]\n",
    "img = net['preprocess'](og)[np.newaxis]\n",
    "\n",
    "fig, axs = plt.subplots(1, len(features), figsize=(20, 10))\n",
    "\n",
    "for i in range(len(features)):\n",
    "    axs[i].set_title(features[i])\n",
    "    grad = plot_gradient(img, x, g.get_tensor_by_name(features[i]), g)\n",
    "    axs[i].imshow(utils.normalize(grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dream(img, gradient, step, net, x, n_iterations=50, plot_step=10):\n",
    "    # Copy the input image as we'll add the gradient to it in a loop\n",
    "    img_copy = img.copy()\n",
    "\n",
    "    fig, axs = plt.subplots(1, n_iterations // plot_step, figsize=(20, 10))\n",
    "\n",
    "    with tf.Session(graph=g) as sess, g.device(device):\n",
    "        for it_i in range(n_iterations):\n",
    "\n",
    "            # This will calculate the gradient of the layer we chose with respect to the input image.\n",
    "            this_res = sess.run(gradient[0], feed_dict={x: img_copy})[0]\n",
    "\n",
    "            # Let's normalize it by the maximum activation\n",
    "            this_res /= (np.max(np.abs(this_res) + 1e-8))\n",
    "            \n",
    "            img_copy += this_res * step\n",
    "\n",
    "            # Plot the image\n",
    "            if (it_i + 1) % plot_step == 0:\n",
    "                m = net['deprocess'](img_copy[0])\n",
    "                axs[it_i // plot_step].imshow(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_iterations = 3\n",
    "\n",
    "\n",
    "step = 1.0\n",
    "\n",
    "# Every 1 iterations, we'll plot the current deep dream\n",
    "plot_step = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for feature_i in range(len(features)):\n",
    "    with tf.Session(graph=g) as sess, g.device(device):\n",
    "        # Get a feature layer\n",
    "        layer = g.get_tensor_by_name(features[feature_i])\n",
    "\n",
    "        gradient = tf.gradients(tf.reduce_mean(layer), x)\n",
    "        \n",
    "        \n",
    "        dream(img, gradient, step, net, x, n_iterations=n_iterations, plot_step=plot_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "og = plt.imread('raj1.jpg')\n",
    "plt.imshow(og)\n",
    "\n",
    "# Preprocess the image and make sure it is 4-dimensional by adding a new axis to the 0th dimension:\n",
    "img = net['preprocess'](og)\n",
    "#xm=img.shape();\n",
    "print(img.shape)\n",
    "#img = img.reshape(1,244,244,3)\n",
    "img = np.expand_dims(img, axis=0)\n",
    "print(img.shape)\n",
    "assert(img.ndim == 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer = g.get_tensor_by_name(names[-2] + \":0\")\n",
    "\n",
    "# And find its shape\n",
    "with tf.Session(graph=g) as sess, g.device(device):\n",
    "    layer_shape = tf.shape(layer).eval(feed_dict={x:img})\n",
    "\n",
    "# We can find out how many neurons it has by feeding it an image and\n",
    "# calculating the shape.  The number of output channels is the last dimension.\n",
    "n_els = layer_shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neuron_i = 2 \n",
    "\n",
    "print(net['labels'][neuron_i])\n",
    "#assert(neuron_i >= 0 and neuron_i < n_els)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# And we'll create an activation of this layer which is very close to 0\n",
    "layer_vec = np.ones(layer_shape) / 100.0\n",
    "\n",
    "# Except for the randomly chosen neuron which will be very close to 1\n",
    "layer_vec[..., neuron_i] = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Explore different parameters for this section.\n",
    "n_iterations = 51\n",
    "\n",
    "plot_step = 5\n",
    "\n",
    "# If you use a different network, you will definitely need to experiment\n",
    "# with the step size, as each network normalizes the input image differently.\n",
    "step = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imgs = []\n",
    "with tf.Session(graph=g) as sess, g.device(device):\n",
    "    gradient = tf.gradients(tf.reduce_max(layer), x)\n",
    "\n",
    "    # Copy the input image as we'll add the gradient to it in a loop\n",
    "    img_copy = img.copy()\n",
    "\n",
    "    with tf.Session(graph=g) as sess, g.device(device):\n",
    "        for it_i in range(n_iterations):\n",
    "\n",
    "            # This will calculate the gradient of the layer we chose with respect to the input image.\n",
    "            this_res = sess.run(gradient[0], feed_dict={\n",
    "                    x: img_copy, layer: layer_vec})[0]\n",
    "            \n",
    "            # Let's normalize it by the maximum activation\n",
    "            this_res /= (np.max(np.abs(this_res) + 1e-8))\n",
    "            \n",
    "            # Or alternatively, we can normalize by standard deviation\n",
    "            # this_res /= (np.std(this_res) + 1e-8)\n",
    "\n",
    "            # Then add the gradient back to the input image\n",
    "            # Think about what this gradient represents?\n",
    "            # It says what direction we should move our input\n",
    "            # in order to meet our objective stored in \"gradient\"\n",
    "            img_copy += this_res * step\n",
    "\n",
    "            # Plot the image\n",
    "            if (it_i + 1) % plot_step == 0:\n",
    "                m = net['deprocess'](img_copy[0])\n",
    "\n",
    "                plt.figure(figsize=(5, 5))\n",
    "                plt.grid('off')\n",
    "                plt.imshow(m)\n",
    "                plt.show()\n",
    "                \n",
    "                imgs.append(m)\n",
    "                "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
